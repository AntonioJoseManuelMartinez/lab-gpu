{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3431319e-2e6b-43c1-a2f6-61ccba592c21",
   "metadata": {},
   "source": [
    "## Evaluating a vectorial function on CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d142183-b6bb-42e7-ba9d-35bf0f91dc0c",
   "metadata": {},
   "source": [
    "### CPU: plain and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92dd336-9997-4323-80e4-f285e9cc2db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "16.4 ms ± 1.6 ms per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "43 ms ± 11.4 ms per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "28.6 ms ± 678 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit, jit\n",
    "\n",
    "# Python plain implementation w/ numba \n",
    "@njit\n",
    "def grade2_vector(x, y, a, b, c):\n",
    "    z = np.zeros(x.size)\n",
    "    for i in range(x.size):\n",
    "        z[i] = a*x[i]*x[i] + b*y[i] + c\n",
    "    return z\n",
    "\n",
    "# Numpy ufunc\n",
    "def grade2_ufunc(x, y, a, b, c):\n",
    "    return a*x**2 + b*y + c\n",
    "\n",
    "# size of the vectors\n",
    "size = 5_000_000\n",
    "\n",
    "# allocating and populating the vectors\n",
    "a_cpu = np.random.rand(size)\n",
    "b_cpu = np.random.rand(size)\n",
    "c_cpu = np.zeros(size)\n",
    "\n",
    "a = 3.5\n",
    "b = 2.8\n",
    "c = 10\n",
    "\n",
    "# Printing input values\n",
    "#print(a_cpu)\n",
    "#print(b_cpu)\n",
    "# Random function in Numpy always use float64\n",
    "print(a_cpu.dtype)\n",
    "\n",
    "c_cpu = grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "\n",
    "# Evaluating the time\n",
    "\n",
    "# Numba Python: huge improvement, better that numpy code\n",
    "%timeit -n 5 -r 2 grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# w/ a numpy ufunc manually coded\n",
    "%timeit -n 5 -r 2 grade2_ufunc(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# using the general numpy ufunc \n",
    "%timeit -n 5 -r 2 a*a_cpu**2 + b*b_cpu + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c776e71-9901-4816-a4bb-f2ce0dd51c6b",
   "metadata": {},
   "source": [
    "### 3.2 A) Celda GPU con CuPy (con y sin copia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ceaf8f-07dc-42d4-9426-73a0d7721870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy con copia CPU->GPU:\n",
      "run_cupy_with_copy  :    CPU: 14012.362 us   +/- 46.721 (min: 13937.715 / max: 14076.917) us     GPU-0: 14019.088 us   +/- 46.764 (min: 13942.816 / max: 14083.168) us\n",
      "\n",
      "CuPy sin copia (solo cálculo en GPU):\n",
      "run_cupy_no_copy    :    CPU:  4288.401 us   +/-  3.499 (min:  4285.424 / max:  4297.566) us     GPU-0:  4292.445 us   +/-  3.693 (min:  4289.280 / max:  4301.824) us\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "from cupyx.profiler import benchmark  # para medir tiempos de GPU :contentReference[oaicite:0]{index=0}\n",
    "\n",
    "# Misma ufunc pero pensada para trabajar con arrays de CuPy\n",
    "def grade2_ufunc_gpu(x, y, a, b, c):\n",
    "    return a * x**2 + b * y + c\n",
    "\n",
    "# CASO 1: CONTANDO LA COPIA CPU -> GPU EN EL TIEMPO \n",
    "\n",
    "def run_cupy_with_copy():\n",
    "    # copiamos los datos de NumPy (CPU) a CuPy (GPU) dentro de la función\n",
    "    x_gpu = cp.asarray(a_cpu)\n",
    "    y_gpu = cp.asarray(b_cpu)\n",
    "    z_gpu = grade2_ufunc_gpu(x_gpu, y_gpu, a, b, c)\n",
    "    # sincronizamos para que acabe el trabajo en la GPU antes de medir\n",
    "    cp.cuda.Stream.null.synchronize()\n",
    "    return z_gpu\n",
    "\n",
    "bench_copy = benchmark(run_cupy_with_copy, (), n_repeat=10)\n",
    "print(\"CuPy con copia CPU->GPU:\")\n",
    "print(bench_copy)\n",
    "\n",
    "\n",
    "# CASO 2: SIN CONTAR LA COPIA (solo cálculo en GPU)\n",
    "\n",
    "# Copiamos solo una vez fuera de la función de benchmark\n",
    "a_gpu = cp.asarray(a_cpu)\n",
    "b_gpu = cp.asarray(b_cpu)\n",
    "\n",
    "def run_cupy_no_copy():\n",
    "    z_gpu = grade2_ufunc_gpu(a_gpu, b_gpu, a, b, c)\n",
    "    cp.cuda.Stream.null.synchronize()\n",
    "    return z_gpu\n",
    "\n",
    "bench_no_copy = benchmark(run_cupy_no_copy, (), n_repeat=10)\n",
    "print(\"\\nCuPy sin copia (solo cálculo en GPU):\")\n",
    "print(bench_no_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997de84c-98ca-4b1a-928e-bfc4dcedd158",
   "metadata": {},
   "source": [
    "### 3.2 B) Celda GPU con Numba @vectorize(target='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d766a8-7b6e-42c3-a20e-3273a202e423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba GPU con copia automática (CPU <-> GPU):\n",
      "run_numba_with_copy :    CPU: 18597.727 us   +/- 2238.902 (min: 15382.026 / max: 21410.432) us     GPU-0: 18606.054 us   +/- 2239.156 (min: 15389.888 / max: 21419.584) us\n",
      "\n",
      "Numba GPU sin contar copia (solo cálculo en GPU):\n",
      "run_numba_no_copy   :    CPU:  2355.255 us   +/- 977.990 (min:  1335.105 / max:  3553.797) us     GPU-0:  2361.178 us   +/- 978.272 (min:  1340.832 / max:  3560.864) us\n"
     ]
    }
   ],
   "source": [
    "from numba import vectorize, cuda\n",
    "\n",
    "# ufunc de Numba que se ejecuta en la GPU\n",
    "@vectorize(['float64(float64, float64, float64, float64, float64)'], target='cuda')\n",
    "def grade2_vector_gpu(x, y, a, b, c):\n",
    "    return a * x * x + b * y + c\n",
    "\n",
    "\n",
    "# CASO 1: Numba con COPIA AUTOMÁTICA (CPU <-> GPU)\n",
    "\n",
    "def run_numba_with_copy():\n",
    "    # Pasamos arrays NumPy; Numba se encarga de copiar a la GPU y devolver a CPU\n",
    "    z = grade2_vector_gpu(a_cpu, b_cpu, a, b, c)\n",
    "    cuda.synchronize()\n",
    "    return z\n",
    "\n",
    "bench_numba_copy = benchmark(run_numba_with_copy, (), n_repeat=10)\n",
    "print(\"Numba GPU con copia automática (CPU <-> GPU):\")\n",
    "print(bench_numba_copy)\n",
    "\n",
    "\n",
    "# CASO 2: sin contar la copia (datos ya en la GPU)\n",
    "\n",
    "# Copiamos primero a GPU como arrays de CuPy\n",
    "a_gpu = cp.asarray(a_cpu)\n",
    "b_gpu = cp.asarray(b_cpu)\n",
    "\n",
    "def run_numba_no_copy():\n",
    "    # Numba puede trabajar con arrays que implementan __cuda_array_interface__,\n",
    "    # como los de CuPy, sin hacer copias extra. :contentReference[oaicite:1]{index=1}\n",
    "    z = grade2_vector_gpu(a_gpu, b_gpu, a, b, c)\n",
    "    cuda.synchronize()\n",
    "    return z\n",
    "\n",
    "bench_numba_no_copy = benchmark(run_numba_no_copy, (), n_repeat=10)\n",
    "print(\"\\nNumba GPU sin contar copia (solo cálculo en GPU):\")\n",
    "print(bench_numba_no_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea6d30-8422-4763-b56d-5b9c1791fd48",
   "metadata": {},
   "source": [
    "### 3.2 C) Comentario de resultados (CPU vs GPU con CuPy y Numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a44aab-968d-4b9b-9797-990835b654d1",
   "metadata": {},
   "source": [
    "\n",
    "En este ejercicio se ha evaluado la función vectorial `z = a*x*x + b*y + c` usando vectores de 5 millones de elementos, comparando la ejecución en CPU y GPU con distintas librerías.\n",
    "\n",
    "---\n",
    "\n",
    "### Resultados en CPU (tiempos medios)\n",
    "\n",
    "- `grade2_vector` con Numba (`@njit`): **16.4 ms ± 1.6 ms**  \n",
    "- `grade2_ufunc` manual en NumPy: **43 ms ± 11.4 ms**  \n",
    "- Expresión NumPy general: **28.6 ms ± 0.7 ms**\n",
    "\n",
    "La versión con Numba en CPU es claramente la más eficiente, muy por delante de las dos variantes en NumPy.\n",
    "\n",
    "---\n",
    "\n",
    "### Resultados en GPU con CuPy\n",
    "\n",
    "- Con copia CPU->GPU incluida: **≈ 14.0 ms**  \n",
    "- Sin copia (datos ya en GPU): **≈ 4.3 ms**\n",
    "\n",
    "Cuando se incluye la copia de datos, el tiempo total es similar al de la mejor versión en CPU, lo que muestra que la transferencia de datos puede compensar la aceleración de la GPU.  \n",
    "Sin embargo, cuando se mide solo el cálculo con los datos ya en la GPU, CuPy es claramente más rápido que cualquier variante en CPU.\n",
    "\n",
    "---\n",
    "\n",
    "### Resultados en GPU con Numba (`@vectorize(target='cuda')`)\n",
    "\n",
    "- Con copia automática CPU<->GPU: **≈ 18.6 ms**  \n",
    "- Sin copia (datos en GPU): **≈ 2.4 ms**\n",
    "\n",
    "La copia automática hace que el tiempo total sea peor que en CPU.  \n",
    "En cambio, cuando los datos ya están en la GPU, Numba obtiene el mejor tiempo de todos, alrededor de 2.4 ms.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusiones\n",
    "\n",
    "- La CPU con Numba (`@njit`) mejora notablemente a NumPy, pero la GPU puede superar claramente a la CPU si se minimizan las copias de datos.\n",
    "- CuPy y Numba en GPU muestran tiempos muy reducidos cuando los arrays residen ya en la GPU.\n",
    "- La mejor ejecución obtenida ha sido la de **Numba en GPU sin copia**, con unos 2.4 ms.\n",
    "- Si las copias CPU↔GPU se incluyen en la medida, la ganancia desaparece o incluso empeora respecto a la CPU, lo que demuestra que el coste de transferencia es crítico en problemas de gran tamaño.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
