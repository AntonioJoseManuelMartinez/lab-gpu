{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "454c61ba-825d-4290-b7ed-135a775fe002",
   "metadata": {},
   "source": [
    "### 3.4) Multiplicación de matrices en GPU con Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8019c56a-e5ce-469b-a406-9c6056ab9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Tamaño de la matriz:\n",
    "# Si el usuario pasa un argumento por línea de comandos, lo usamos como n.\n",
    "# Si no, usamos un valor por defecto para ejecutar el notebook.\n",
    "if len(sys.argv) > 1:\n",
    "    n = int(sys.argv[1])\n",
    "    print(\"Tamaño de las matrices (n) leído por línea de comandos:\", n)\n",
    "else:\n",
    "    n = 7000\n",
    "    print(\"Tamaño de las matrices (n) por defecto:\", n)\n",
    "    \n",
    "A = np.random.rand(n, n).astype(np.float32)\n",
    "B = np.random.rand(n, n).astype(np.float32)\n",
    "\n",
    "C = np.dot(A, B)  # warm-up and Matrix multiplication\n",
    "\n",
    "%timeit -r 2 -o np.dot(A, B)\n",
    "\n",
    "print(f\"Result shape (Numpy): {C.shape}\")\n",
    "print(f\"Result type (Numpy): {C.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e220304-9bec-4755-94da-912417b3cbfe",
   "metadata": {},
   "source": [
    "### Multiplicación de matrices en GPU con PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35248dd9-2cb9-4715-bfa3-bd314434fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Seleccionamos el dispositivo: GPU si está disponible (bohr-gpu), si no CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Usando dispositivo:\", device)\n",
    "\n",
    "# Usamos el mismo n que se ha leído con sys.argv (o 7000 por defecto)\n",
    "print(\"Tamaño de las matrices (n) en PyTorch:\", n)\n",
    "\n",
    "# Creamos las matrices directamente en el dispositivo (idealmente en la GPU)\n",
    "A_t = torch.rand((n, n), dtype=torch.float32, device=device)\n",
    "B_t = torch.rand((n, n), dtype=torch.float32, device=device)\n",
    "\n",
    "# Multiplicación de matrices con PyTorch (warm-up)\n",
    "C_t = torch.matmul(A_t, B_t)\n",
    "\n",
    "def matmul_torch():\n",
    "    C = torch.matmul(A_t, B_t)\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    return C\n",
    "\n",
    "print(\"Midiendo tiempo de torch.matmul(A_t, B_t)...\")\n",
    "%timeit -r 2 -o matmul_torch()\n",
    "\n",
    "print(f\"Result shape (PyTorch): {C_t.shape}\")\n",
    "print(f\"Result type (PyTorch): {C_t.dtype}\")\n",
    "print(f\"Stored on device: {C_t.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a32001-f1af-47cc-8ee5-41fe8b2c182d",
   "metadata": {},
   "source": [
    "### 3.4) Multiplicación de matrices con Numpy y PyTorch en GPU (resultados - extra)\n",
    "\n",
    "Para esta actividad extra se ha modificado el notebook original de multiplicación de matrices para permitir que el tamaño `n` de las matrices cuadradas pueda ser proporcionado por el usuario desde la línea de comandos. De este modo, al lanzar el notebook mediante `sbatch` e `ipython`, es posible seleccionar dinámicamente el tamaño de la operación, lo que facilita experimentar con distintos valores de `n` sin editar el código.\n",
    "\n",
    "Una vez incorporada esta mejora, se ha comparado la multiplicación de matrices en NumPy (CPU) con su equivalente en PyTorch utilizando la GPU del nodo `bohr-gpu`. A continuación se resumen los resultados obtenidos para dos tamaños de matriz.\n",
    "\n",
    "---\n",
    "\n",
    "#### Caso 1: n = 4000\n",
    "\n",
    "- **NumPy (CPU)**  \n",
    "  Tiempo medio: **151 ms**\n",
    "\n",
    "- **PyTorch (GPU)**  \n",
    "  Tiempo medio: **9.89 ms**\n",
    "\n",
    "- **Aceleración aproximada:** ~15×  \n",
    "  PyTorch realiza toda la operación en la GPU (`cuda:0`), manteniendo el resultado en `float32` y acelerando notablemente el cálculo frente a NumPy.\n",
    "\n",
    "---\n",
    "\n",
    "#### Caso 2: n = 7000\n",
    "\n",
    "- **NumPy (CPU)**  \n",
    "  Tiempo medio: **569 ms**\n",
    "\n",
    "- **PyTorch (GPU)**  \n",
    "  Tiempo medio: **50.4 ms**\n",
    "\n",
    "- **Aceleración aproximada:** ~11×  \n",
    "  Para tamaños grandes, la GPU muestra un rendimiento muy superior debido a su capacidad de procesamiento masivamente paralelo.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "La incorporación del parámetro `n` a través de la línea de comandos permite ajustar fácilmente el tamaño de las matrices durante la ejecución en `bohr-gpu`, sin necesidad de modificar el código del notebook. Esto facilita la evaluación comparativa entre CPU y GPU para distintos volúmenes de datos.\n",
    "\n",
    "Los resultados muestran que, para operaciones de multiplicación de matrices de gran tamaño, la ejecución en GPU mediante PyTorch presenta tiempos de cálculo sustancialmente inferiores a los obtenidos con NumPy en CPU. En los casos probados (n = 4000 y n = 7000), PyTorch reduce el tiempo total de la operación en aproximadamente un orden de magnitud, manteniendo la precisión numérica y el formato de datos (`float32`). Esta diferencia se debe al aprovechamiento del paralelismo masivo de la GPU en operaciones intensivas de álgebra lineal.\n",
    "\n",
    "En conjunto, los experimentos ilustran cómo PyTorch puede emplearse como una alternativa eficiente para realizar cálculos matriciales a gran escala cuando se dispone de hardware acelerador.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
